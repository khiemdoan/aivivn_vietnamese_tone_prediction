{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMmcoSCN40TH",
        "colab_type": "text"
      },
      "source": [
        "# Mount ổ Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "40aQkXxQHRCy",
        "colab_type": "code",
        "outputId": "846b6d40-4d50-4ed2-d9d4-46df8ea1be4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "try:\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir('/content/drive/My Drive/aivivn_vietnamese_tone_prediction/')\n",
        "    print(f'Current working dir: {os.getcwd()}')\n",
        "except ImportError:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current working dir: /content/drive/My Drive/aivivn_vietnamese_tone_prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47lSXEmIKyNP",
        "colab_type": "text"
      },
      "source": [
        "# Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_OPI621K0-B",
        "colab_type": "code",
        "outputId": "f52cdd04-58ea-404f-d4d1-7069be4a46be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import itertools\n",
        "import platform\n",
        "import random\n",
        "import string\n",
        "import time\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from model import EncoderRNN, LuongAttnDecoderRNN, SentenceDataSet\n",
        "from utils import as_minutes, device, get_display, model_dir, n_grams, time_since\n",
        "from vietnamese_utils import remove_vietnamese_tone, uni_chars_l\n",
        "from vocab import PAD_token, SOS_token, Vocab\n",
        "\n",
        "print(f'Python version: {platform.python_version()}')\n",
        "print(f'Pytorch version: {torch.__version__}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.6.8\n",
            "Pytorch version: 1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wrsQ1Wg4vsI",
        "colab_type": "text"
      },
      "source": [
        "# Chuẩn bị bộ từ điển"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3GXt74W4t4v",
        "colab_type": "code",
        "outputId": "87313b70-165d-4548-f8c5-025fdcadae9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chars = string.ascii_lowercase\n",
        "chars += uni_chars_l\n",
        "chars += ' '\n",
        "\n",
        "vocab = Vocab()\n",
        "for c in chars:\n",
        "    vocab.add_char(c)\n",
        "\n",
        "print(f'Tổng số ký tự trong từ điển: {vocab.num_words}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tổng số ký tự trong từ điển: 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LQZJJja5NKY",
        "colab_type": "text"
      },
      "source": [
        "# Tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec5sWBoW5RTI",
        "colab_type": "text"
      },
      "source": [
        "## Đọc dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw2LXThP5UAQ",
        "colab_type": "code",
        "outputId": "165c3096-d145-4c22-8463-24a5a9ac24e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# with ZipFile('data/vietnamese_tone_prediction.zip', 'r') as inzip:\n",
        "#     data = inzip.read('train.txt').decode('utf-8').split('\\n')\n",
        "#     data = data[:500_000]\n",
        "\n",
        "with open('data/mini_train.txt', 'r', encoding='utf-8') as infile:\n",
        "    data = infile.read().split('\\n')\n",
        "\n",
        "print(f'Số câu được load: {len(data):_}')\n",
        "pprint(data[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Số câu được load: 196_341\n",
            "['Alaska ngày 21 tháng 9 năm 2007',\n",
            " 'Những kiểu áo sơ mi may theo chất liệu cotton',\n",
            " 'Sau này mới thấy người ta nói',\n",
            " 'Giờ Đại tướng đã đi xa',\n",
            " 'người bị tố cáo lại cũng chủ yếu là các đơn vị']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud02WeBcN3PV",
        "colab_type": "text"
      },
      "source": [
        "## Sinh tập training data set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl3wn9sP5s_v",
        "colab_type": "code",
        "outputId": "f8e9f485-4979-449f-dc4c-870cf50a6538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# chuyển tập dữ liệu về lower case\n",
        "data = [s.lower() for s in data]\n",
        "\n",
        "# Tách ra theo ngram\n",
        "train_grams = list(itertools.chain.from_iterable([n_grams(item) for item in data]))\n",
        "\n",
        "# Sinh tập dữ liệu không dấu\n",
        "train_rev_accent = [remove_vietnamese_tone(item) for item in train_grams]\n",
        "\n",
        "pairs = list(zip(train_rev_accent, train_grams))\n",
        "\n",
        "training_dataset = SentenceDataSet(pairs)\n",
        "\n",
        "# Print some pairs to validate\n",
        "print(f'Kích thước tập train: {len(training_dataset):_}')\n",
        "pprint(training_dataset[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kích thước tập train: 938_742\n",
            "[('alaska ngay 21 thang', 'alaska ngày 21 tháng'),\n",
            " ('ngay 21 thang 9', 'ngày 21 tháng 9'),\n",
            " ('21 thang 9 nam', '21 tháng 9 năm'),\n",
            " ('thang 9 nam 2007', 'tháng 9 năm 2007'),\n",
            " ('nhung kieu ao so', 'những kiểu áo sơ')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFBRSG-0OtWE",
        "colab_type": "text"
      },
      "source": [
        "# Định nghĩa các hàm chuyển text -> vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O8Mq5z8O1mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Padding thêm 0 vào list nào có độ dài nhỏ hơn về phía bên phải\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=vocab.char2index(fillvalue)))\n",
        "\n",
        "\n",
        "# Tạo ma trận binary có kích thước như ma trận truyền vào l nhưng giá trị của mỗi phần tử đánh dấu 1 hoặc 0 tương ứng với padding hoặc không padding\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == vocab.char2index(PAD_token):\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "\n",
        "# Returns padded input sequence tensor and lengths\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [voc.sentence2indexes(sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "\n",
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [voc.sentence2indexes(sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.ByteTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "\n",
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncWv-Hod4vIT",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N8NfLHTMqeH",
        "colab_type": "text"
      },
      "source": [
        "## Định nghĩa hàm loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0r5sBoBO04p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "O0yBm23xHRC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip):\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.tensor([[vocab.char2index(SOS_token)] * batch_size], dtype=torch.long)\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.tensor([[topi[i][0] for i in range(batch_size)]], dtype=torch.long)\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals\n",
        "\n",
        "\n",
        "def trainIters(voc, data_loader,\n",
        "               embedding, encoder, decoder,\n",
        "               encoder_optimizer, decoder_optimizer,\n",
        "               save_dir, batch_size, clip, total_epoch):\n",
        "    print('Training...')\n",
        "    epoch_status = get_display('Epoch: 0')\n",
        "    batch_status = get_display('Batch: 0')\n",
        "    save_status = get_display('Saved epoch: 0')\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(1, total_epoch + 1):\n",
        "        epoch_status.update(f'Training epoch: {epoch}')\n",
        "\n",
        "        print_loss = 0\n",
        "        total_batch = 0\n",
        "        start_batch_time = time.time()\n",
        "        for it, pairs in enumerate(data_loader, 1):\n",
        "            if len(pairs[0]) != batch_size:\n",
        "                continue\n",
        "            training_batch = batch2TrainData(voc, list(zip(*pairs)))\n",
        "            # Extract fields from batch\n",
        "            input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "            # Run a training iteration with batch\n",
        "            loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                         decoder, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "            s, es, rs = time_since(start_batch_time, it / len(data_loader))\n",
        "            batch_status.update(f'Batch: {it}/{len(data_loader)}, loss: {loss:.4f},'\n",
        "                                f' {as_minutes(s)}/{as_minutes(es)}, remain {as_minutes(rs)}, {as_minutes(s / it)}/it')\n",
        "            print_loss += loss\n",
        "            total_batch += 1\n",
        "\n",
        "        # Save checkpoint\n",
        "        save_dir = Path(save_dir)\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        print_loss_avg = print_loss / total_batch\n",
        "        save_file = save_dir / f'checkpoint_epoch_{epoch}_loss_{print_loss_avg:.4f}.pt'\n",
        "        save_content = {\n",
        "            'epoch': epoch,\n",
        "            'en': encoder.state_dict(),\n",
        "            'de': decoder.state_dict(),\n",
        "            'en_opt': encoder_optimizer.state_dict(),\n",
        "            'de_opt': decoder_optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'voc_dict': voc.__dict__,\n",
        "            'embedding': embedding.state_dict()\n",
        "        }\n",
        "        torch.save(save_content, save_file)\n",
        "        save_status.update(f'Saved epoch: {epoch}, average loss: {print_loss_avg:.4f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbWWiKU5PWfA",
        "colab_type": "code",
        "outputId": "1d4a9851-fb69-497b-e40a-67b87adc5f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Configure models\n",
        "attn_model = 'dot'\n",
        "# attn_model = 'general'\n",
        "# attn_model = 'concat'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 100\n",
        "total_epoch = 10\n",
        "\n",
        "# Configure training/optimization\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(vocab.num_words, hidden_size)\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, vocab.num_words, decoder_n_layers, dropout)\n",
        "\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Models built and ready to go!')\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "\n",
        "training_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Run training iterations\n",
        "print(\"Starting Training!\")\n",
        "trainIters(vocab, training_loader,\n",
        "           embedding, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           model_dir, batch_size, clip, total_epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Training epoch: 7'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Batch: 8105/9388, loss: 0.1038, 32m 59s/38m 12s, remain 5m 13s, 0m 0s/it'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Saved epoch: 6, average loss: 0.1143'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}