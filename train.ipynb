{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"colab":{"name":"train.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PMmcoSCN40TH","colab_type":"text"},"source":["# Mount ổ Google Drive"]},{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"40aQkXxQHRCy","colab_type":"code","outputId":"30dd8955-ca31-4eb3-8852-1228d4848686","executionInfo":{"status":"ok","timestamp":1568217372132,"user_tz":-420,"elapsed":2021,"user":{"displayName":"Khiêm Đoàn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlerHhg-PDAdPpb9nbzE2mp2ZQso6H5rrCa8J3XA=s64","userId":"08869694981109897594"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["try:\n","    import os\n","    from google.colab import drive\n","\n","    drive.mount('/content/drive')\n","    os.chdir('/content/drive/My Drive/aivivn_vietnamese_tone_prediction/')\n","    print(f'Current working dir: {os.getcwd()}')\n","except ImportError:\n","    pass"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Current working dir: /content/drive/My Drive/aivivn_vietnamese_tone_prediction\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"47lSXEmIKyNP","colab_type":"text"},"source":["# Import thư viện"]},{"cell_type":"code","metadata":{"id":"D_OPI621K0-B","colab_type":"code","outputId":"728b4de7-0612-43a6-d674-f30e2a56c606","executionInfo":{"status":"ok","timestamp":1568217376356,"user_tz":-420,"elapsed":6215,"user":{"displayName":"Khiêm Đoàn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlerHhg-PDAdPpb9nbzE2mp2ZQso6H5rrCa8J3XA=s64","userId":"08869694981109897594"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import itertools\n","import platform\n","import random\n","import string\n","import time\n","from pathlib import Path\n","from pprint import pprint\n","from zipfile import ZipFile\n","\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","\n","from model import EncoderRNN, LuongAttnDecoderRNN, SentenceDataSet\n","from utils import as_minutes, device, get_display, model_dir, n_grams, time_since\n","from vietnamese_utils import remove_vietnamese_tone, uni_chars_l\n","from vocab import PAD_token, SOS_token, Vocab\n","\n","print(f'Python version: {platform.python_version()}')\n","print(f'Pytorch version: {torch.__version__}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Python version: 3.6.8\n","Pytorch version: 1.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2wrsQ1Wg4vsI","colab_type":"text"},"source":["# Chuẩn bị bộ từ điển"]},{"cell_type":"code","metadata":{"id":"c3GXt74W4t4v","colab_type":"code","outputId":"fdf130fe-a54f-4b8e-8f71-2cbccd7a974a","executionInfo":{"status":"ok","timestamp":1568217376359,"user_tz":-420,"elapsed":6111,"user":{"displayName":"Khiêm Đoàn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlerHhg-PDAdPpb9nbzE2mp2ZQso6H5rrCa8J3XA=s64","userId":"08869694981109897594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["chars = string.ascii_lowercase\n","chars += uni_chars_l\n","chars += ' '\n","\n","vocab = Vocab()\n","for c in chars:\n","    vocab.add_char(c)\n","\n","print(f'Tổng số ký tự trong từ điển: {vocab.num_words}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tổng số ký tự trong từ điển: 98\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0LQZJJja5NKY","colab_type":"text"},"source":["# Tiền xử lý dữ liệu"]},{"cell_type":"markdown","metadata":{"id":"Ec5sWBoW5RTI","colab_type":"text"},"source":["## Đọc dữ liệu"]},{"cell_type":"code","metadata":{"id":"Pw2LXThP5UAQ","colab_type":"code","outputId":"481d0c79-f344-4d3c-8427-00956883a839","executionInfo":{"status":"ok","timestamp":1568217379006,"user_tz":-420,"elapsed":8729,"user":{"displayName":"Khiêm Đoàn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlerHhg-PDAdPpb9nbzE2mp2ZQso6H5rrCa8J3XA=s64","userId":"08869694981109897594"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["with open('data/train.txt', 'r', encoding='utf-8') as infile:\n","    data = infile.read().split('\\n')\n","\n","print(f'Số câu được load: {len(data):_}')\n","pprint(data[:5])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Số câu được load: 878_760\n","['Sau khi xong việc, ông Đức đã nhận 2,8 triệu đồng từ bà Tiến.',\n"," 'Galago matschiei là một loài động vật có vú trong họ Galagidae, bộ Linh '\n"," 'trưởng.',\n"," 'Loài này được (Bunge) Kuntze mô tả khoa học đầu tiên năm 1891.',\n"," 'Khi hai đội còn đang giằng co thì bất ngờ Stoke có bàn thắng mở tỉ số.',\n"," 'Sau chiếc sạc iPhone/iPod thì đây là tác phẩm mới nhất của Thin Gypsy Thief.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ud02WeBcN3PV","colab_type":"text"},"source":["## Sinh tập training data set\n","\n"]},{"cell_type":"code","metadata":{"id":"zl3wn9sP5s_v","colab_type":"code","outputId":"07a7e4de-433c-46b0-dddb-7696acbe4334","executionInfo":{"status":"ok","timestamp":1568217437185,"user_tz":-420,"elapsed":66883,"user":{"displayName":"Khiêm Đoàn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlerHhg-PDAdPpb9nbzE2mp2ZQso6H5rrCa8J3XA=s64","userId":"08869694981109897594"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# chuyển tập dữ liệu về lower case\n","data = [s.lower() for s in data]\n","\n","# Tách ra theo ngram\n","train_grams = list(itertools.chain.from_iterable([n_grams(item) for item in data]))\n","\n","# Sinh tập dữ liệu không dấu\n","train_rev_accent = [remove_vietnamese_tone(item) for item in train_grams]\n","\n","pairs = list(zip(train_rev_accent, train_grams))\n","del train_rev_accent, train_grams\n","\n","training_dataset = SentenceDataSet(pairs)\n","\n","# Print some pairs to validate\n","print(f'Kích thước tập train: {len(training_dataset):_}')\n","pprint(training_dataset[:5])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Kích thước tập train: 13_013_564\n","[('sau khi xong viec,', 'sau khi xong việc,'),\n"," ('khi xong viec, ong', 'khi xong việc, ông'),\n"," ('xong viec, ong duc', 'xong việc, ông đức'),\n"," ('viec, ong duc da', 'việc, ông đức đã'),\n"," ('ong duc da nhan', 'ông đức đã nhận')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DFBRSG-0OtWE","colab_type":"text"},"source":["# Định nghĩa các hàm chuyển text -> vector"]},{"cell_type":"code","metadata":{"id":"0O8Mq5z8O1mp","colab_type":"code","colab":{}},"source":["# Padding thêm 0 vào list nào có độ dài nhỏ hơn về phía bên phải\n","def zeroPadding(l, fillvalue=PAD_token):\n","    return list(itertools.zip_longest(*l, fillvalue=vocab.char2index(fillvalue)))\n","\n","\n","# Tạo ma trận binary có kích thước như ma trận truyền vào l nhưng giá trị của mỗi phần tử đánh dấu 1 hoặc 0 tương ứng với padding hoặc không padding\n","def binaryMatrix(l, value=PAD_token):\n","    m = []\n","    for i, seq in enumerate(l):\n","        m.append([])\n","        for token in seq:\n","            if token == vocab.char2index(PAD_token):\n","                m[i].append(0)\n","            else:\n","                m[i].append(1)\n","    return m\n","\n","\n","# Returns padded input sequence tensor and lengths\n","def inputVar(l, voc):\n","    indexes_batch = [voc.sentence2indexes(sentence) for sentence in l]\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, lengths\n","\n","\n","# Returns padded target sequence tensor, padding mask, and max target length\n","def outputVar(l, voc):\n","    indexes_batch = [voc.sentence2indexes(sentence) for sentence in l]\n","    max_target_len = max([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    mask = binaryMatrix(padList)\n","    mask = torch.ByteTensor(mask)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, mask, max_target_len\n","\n","\n","# Returns all items for a given batch of pairs\n","def batch2TrainData(voc, pair_batch):\n","    pair_batch.sort(key=lambda x: len(x[0]), reverse=True)\n","    input_batch, output_batch = [], []\n","    for pair in pair_batch:\n","        input_batch.append(pair[0])\n","        output_batch.append(pair[1])\n","    inp, lengths = inputVar(input_batch, voc)\n","    output, mask, max_target_len = outputVar(output_batch, voc)\n","    return inp, lengths, output, mask, max_target_len"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ncWv-Hod4vIT","colab_type":"text"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"0N8NfLHTMqeH","colab_type":"text"},"source":["## Định nghĩa hàm loss"]},{"cell_type":"code","metadata":{"id":"L0r5sBoBO04p","colab_type":"code","colab":{}},"source":["def maskNLLLoss(inp, target, mask):\n","    nTotal = mask.sum()\n","    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n","    loss = crossEntropy.masked_select(mask).mean()\n","    loss = loss.to(device)\n","    return loss, nTotal.item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"O0yBm23xHRC5","colab_type":"code","colab":{}},"source":["def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder,\n","          encoder_optimizer, decoder_optimizer, batch_size, clip):\n","    # Zero gradients\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    # Set device options\n","    input_variable = input_variable.to(device)\n","    lengths = lengths.to(device)\n","    target_variable = target_variable.to(device)\n","    mask = mask.to(device)\n","\n","    # Initialize variables\n","    loss = 0\n","    print_losses = []\n","    n_totals = 0\n","\n","    # Forward pass through encoder\n","    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n","\n","    # Create initial decoder input (start with SOS tokens for each sentence)\n","    decoder_input = torch.tensor([[vocab.char2index(SOS_token)] * batch_size], dtype=torch.long)\n","    decoder_input = decoder_input.to(device)\n","\n","    # Set initial decoder hidden state to the encoder's final hidden state\n","    decoder_hidden = encoder_hidden[:decoder.n_layers]\n","\n","    # Determine if we are using teacher forcing this iteration\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    # Forward batch of sequences through decoder one time step at a time\n","    if use_teacher_forcing:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # Teacher forcing: next input is current target\n","            decoder_input = target_variable[t].view(1, -1)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","    else:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # No teacher forcing: next input is decoder's own current output\n","            _, topi = decoder_output.topk(1)\n","            decoder_input = torch.tensor([[topi[i][0] for i in range(batch_size)]], dtype=torch.long)\n","            decoder_input = decoder_input.to(device)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","\n","    # Perform backpropatation\n","    loss.backward()\n","\n","    # Clip gradients: gradients are modified in place\n","    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n","    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n","\n","    # Adjust model weights\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return sum(print_losses) / n_totals\n","\n","\n","def trainIters(voc, data_loader,\n","               embedding, encoder, decoder,\n","               encoder_optimizer, decoder_optimizer,\n","               save_dir, batch_size, clip, total_epoch, save_every):\n","    print('Training...')\n","    epoch_status = get_display('Epoch: 0')\n","    batch_status = get_display('Batch: 0')\n","    save_status = get_display('Saved epoch: 0')\n","\n","    print_loss = 0\n","    total_batch = 0\n","\n","    # Training loop\n","    for epoch in range(1, total_epoch + 1):\n","        epoch_status.update(f'Training epoch: {epoch}')\n","\n","        n_iter = 0\n","\n","        start_batch_time = time.time()\n","        for it, pairs in enumerate(data_loader, 1):\n","            if len(pairs[0]) != batch_size:\n","                continue\n","            training_batch = batch2TrainData(voc, list(zip(*pairs)))\n","            # Extract fields from batch\n","            input_variable, lengths, target_variable, mask, max_target_len = training_batch\n","\n","            # Run a training iteration with batch\n","            loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n","                         decoder, encoder_optimizer, decoder_optimizer, batch_size, clip)\n","            s, es, rs = time_since(start_batch_time, it / len(data_loader))\n","\n","            print_loss += loss\n","            total_batch += 1\n","            n_iter += 1\n","\n","            if n_iter % 10 == 0:\n","                batch_status.update(f'Batch: {it}/{len(data_loader)}, loss: {loss:.4f},'\n","                                    f' {as_minutes(s)}/{as_minutes(es)}, remain {as_minutes(rs)},'\n","                                    f' {as_minutes(s / it)}/it')\n","\n","            if n_iter % save_every == 0:\n","                # Save checkpoint\n","                save_dir = Path(save_dir)\n","                save_dir.mkdir(parents=True, exist_ok=True)\n","                print_loss_avg = print_loss / total_batch\n","                save_file = save_dir / f'checkpoint_epoch_{epoch}_n_iter_{n_iter}_loss_{print_loss_avg:.4f}.pt'\n","                save_content = {\n","                    'epoch': epoch,\n","                    'en': encoder.state_dict(),\n","                    'de': decoder.state_dict(),\n","                    'en_opt': encoder_optimizer.state_dict(),\n","                    'de_opt': decoder_optimizer.state_dict(),\n","                    'loss': loss,\n","                    'voc_dict': voc.__dict__,\n","                    'embedding': embedding.state_dict()\n","                }\n","                torch.save(save_content, save_file)\n","                save_status.update(f'Saved epoch: {epoch}, average loss: {print_loss_avg:.4f}')\n","\n","                print_loss = 0\n","                total_batch = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbWWiKU5PWfA","colab_type":"code","outputId":"1a0bca2c-2af6-4da6-8328-c153475030c1","executionInfo":{"status":"ok","timestamp":1568047706821,"user_tz":-420,"elapsed":16373,"user":{"displayName":"Khiêm Đoàn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlerHhg-PDAdPpb9nbzE2mp2ZQso6H5rrCa8J3XA=s64","userId":"08869694981109897594"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Configure models\n","attn_model = 'dot'\n","# attn_model = 'general'\n","# attn_model = 'concat'\n","embedding_dim = 64\n","hidden_size = 512\n","encoder_n_layers = 2\n","decoder_n_layers = 2\n","dropout = 0.1\n","batch_size = 256\n","save_every = 1000\n","total_epoch = 10\n","\n","# Configure training/optimization\n","clip = 50.0\n","teacher_forcing_ratio = 1.0\n","learning_rate = 0.0001\n","decoder_learning_ratio = 5.0\n","\n","print('Building encoder and decoder ...')\n","# Initialize word embeddings\n","embedding = nn.Embedding(vocab.num_words, embedding_dim)\n","encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n","decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, vocab.num_words, decoder_n_layers, dropout)\n","\n","# Use appropriate device\n","encoder = encoder.to(device)\n","decoder = decoder.to(device)\n","print('Models built and ready to go!')\n","\n","# Ensure dropout layers are in train mode\n","encoder.train()\n","decoder.train()\n","\n","# Initialize optimizers\n","print('Building optimizers ...')\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","\n","training_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Run training iterations\n","print(\"Starting Training!\")\n","trainIters(vocab, training_loader,\n","           embedding, encoder, decoder, encoder_optimizer, decoder_optimizer,\n","           model_dir, batch_size, clip, total_epoch, save_every)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Building encoder and decoder ...\n","Models built and ready to go!\n","Building optimizers ...\n","Starting Training!\n","Training...\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["'Training epoch: 2'"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["'Batch: 6980/50835, loss: 0.0920, 53m 54s/392m 33s, remain 338m 39s, 0m 0s/it'"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["'Saved epoch: 2, average loss: 0.0939'"]},"metadata":{"tags":[]}}]}]}